https://github.com/layer6ai-labs/RecSys2019
http://www.cs.toronto.edu/~mvolkovs/recsys2019_challenge.pdf

256GB RAM
Feature Extraction with a lot re-used features then summarized features. 
pipeline: data parsing, feature extraction, validation (and submission)

XGB model:
extreme gradient boosting 
boosting:
tree method:

tree boosting:

base learner/weak learner:

ensemble model:

gradient boosting:

regularization:

bias variance decomposition:

XGBoosting vs MART:
1. algorithm wise:
2. regularization wise:

why XGBoosting is the most popular tool currently? 


